name: "image-text"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "data/MSCOCO_Images_Texts_Label_train_lmdb"
    batch_size: 1500
    backend: LMDB
  }
}

## we do not test the model during the training stage.
layer {
  name: "test_data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "data/MSCOCO_Images_Texts_Label_train_lmdb"
    batch_size: 1500
    backend: LMDB
  }
}

## slip image and text features
layer {
  name: "slice"
  type: "Slice"
  bottom: "data"
  top: "img_data"
  top: "text_data"
  slice_param {
    slice_dim: 1
    slice_point: 2048 ## 2048-Dim image feature based on ResNet; 6000-Dim text feature based o HGLMM 
  }
}

## data batch norm
layer {
   bottom: "img_data"
   top: "img_data_bnorm"
   name: "img_data_bnorm"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_data_bnorm"
   top: "img_data_bnorm"
   name: "scale_img_data_bnorm"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
   bottom: "text_data"
   top: "text_data_bnorm"
   name: "text_data_bnorm"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_data_bnorm"
   top: "text_data_bnorm"
   name: "scale_text_data_bnorm"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}

## image branch
layer {
  name: "img_fc1"
  type: "InnerProduct"
  bottom: "img_data_bnorm"
  top: "img_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "img_relu1"
  type: "ReLU"
  bottom: "img_fc1"
  top: "img_fc1"
}
layer {
  name: "img_drop1"
  type: "Dropout"
  bottom: "img_fc1"
  top: "img_fc1"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "img_fc2"
  type: "InnerProduct"
  bottom: "img_fc1"
  top: "img_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "img_fc2"
   top: "img_bnorm2"
   name: "img_bnorm2"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_bnorm2"
   top: "img_bnorm2"
   name: "scale_img_bnorm2"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "img_relu2"
  type: "ReLU"
  bottom: "img_bnorm2"
  top: "img_bnorm2"
}

layer {
  name: "img_fc3_t0"
  type: "InnerProduct"
  bottom: "img_bnorm2"
  top: "img_fc3_t0"
  param {
    name: "img_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "img_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "img_fc3_t0"
   top: "img_bnorm3_t0"
   name: "img_bnorm3_t0"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_bnorm3_t0"
   top: "img_bnorm3_t0"
   name: "scale_img_bnorm3_t0"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "img_relu3_t0"
  type: "ReLU"
  bottom: "img_bnorm3_t0"
  top: "img_bnorm3_t0"
}
## identity addition
layer {
   bottom: "img_bnorm2"
   bottom: "img_bnorm3_t0"
   top: "img_fc3_t0_res"
   name: "img_fc3_t0_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## recurrent, t=1
layer {
  name: "img_fc3_t1"
  type: "InnerProduct"
  bottom: "img_fc3_t0_res"
  top: "img_fc3_t1"
  param {
    name: "img_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "img_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "img_fc3_t1"
   top: "img_bnorm3_t1"
   name: "img_bnorm3_t1"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_bnorm3_t1"
   top: "img_bnorm3_t1"
   name: "scale_img_bnorm3_t1"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "img_relu3_t1"
  type: "ReLU"
  bottom: "img_bnorm3_t1"
  top: "img_bnorm3_t1"
}
## identity addition
layer {
   bottom: "img_fc3_t0_res"
   bottom: "img_bnorm3_t1"
   top: "img_fc3_t1_res"
   name: "img_fc3_t1_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## recurrent, t=2
layer {
  name: "img_fc3_t2"
  type: "InnerProduct"
  bottom: "img_fc3_t1_res"
  top: "img_fc3_t2"
  param {
    name: "img_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "img_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "img_fc3_t2"
   top: "img_bnorm3_t2"
   name: "img_bnorm3_t2"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_bnorm3_t2"
   top: "img_bnorm3_t2"
   name: "scale_img_bnorm3_t2"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "img_relu3_t2"
  type: "ReLU"
  bottom: "img_bnorm3_t2"
  top: "img_bnorm3_t2"
}
## identity addition
layer {
   bottom: "img_fc3_t1_res"
   bottom: "img_bnorm3_t2"
   top: "img_fc3_t2_res"
   name: "img_fc3_t2_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## recurrent, t=3
layer {
  name: "img_fc3_t3"
  type: "InnerProduct"
  bottom: "img_fc3_t2_res"
  top: "img_fc3_t3"
  param {
    name: "img_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "img_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "img_fc3_t3"
   top: "img_bnorm3_t3"
   name: "img_bnorm3_t3"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_bnorm3_t3"
   top: "img_bnorm3_t3"
   name: "scale_img_bnorm3_t3"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "img_relu3_t3"
  type: "ReLU"
  bottom: "img_bnorm3_t3"
  top: "img_bnorm3_t3"
}
## identity addition
layer {
   bottom: "img_fc3_t2_res"
   bottom: "img_bnorm3_t3"
   top: "img_fc3_t3_res"
   name: "img_fc3_t3_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## Convolutional Fusion
layer {
  name: "img_fc3_t0_res_re"
  type: "Reshape"
  bottom: "img_fc3_t0_res"
  top: "img_fc3_t0_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
layer {
  name: "img_fc3_t1_res_re"
  type: "Reshape"
  bottom: "img_fc3_t1_res"
  top: "img_fc3_t1_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
layer {
  name: "img_fc3_t2_res_re"
  type: "Reshape"
  bottom: "img_fc3_t2_res"
  top: "img_fc3_t2_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
layer {
  name: "img_fc3_t3_res_re"
  type: "Reshape"
  bottom: "img_fc3_t3_res"
  top: "img_fc3_t3_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
## Stack 
layer {
  name: "img_fc3_res_stack"
  bottom: "img_fc3_t0_res_re"
  bottom: "img_fc3_t1_res_re"
  bottom: "img_fc3_t2_res_re"
  bottom: "img_fc3_t3_res_re"
  top: "img_fc3_res_stack"
  type: "Concat"
  concat_param {
    concat_dim: 1
  }
}
layer { 
  name: 'img_fc3_res_weight' 
  type: "Convolution" 
  bottom: 'img_fc3_res_stack' 
  top: 'img_fc3_res_weight'
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
  convolution_param {
    num_output: 1
    kernel_size: 1
    pad: 0
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: 'img_fc3_res_weight'
   top: 'img_fc3_res_weight_bnorm'
   name: 'img_fc3_res_weight_bnorm'
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: 'img_fc3_res_weight_bnorm'
   top: 'img_fc3_res_weight_bnorm'
   name: "scale_img_fc3_res_weight_bnorm"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "relu_img_fc3_res_weight_bnorm"
  type: "ReLU"
  bottom: 'img_fc3_res_weight_bnorm'
  top: 'img_fc3_res_weight_bnorm'
}
layer {
  name: "img_fc3_res_weight_re"
  type: "Reshape"
  bottom: 'img_fc3_res_weight_bnorm'
  top: "img_fc3_res_weight_bnorm_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 512
      dim: 1
      dim: 1
    } 
  }
}
## End for fusion module

layer {
  name: "img_fc4"
  type: "InnerProduct"
  bottom: "img_fc3_res_weight_bnorm_re"
  top: "img_fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "img_fc4"
   top: "img_bnorm4"
   name: "img_bnorm4"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "img_bnorm4"
   top: "img_bnorm4"
   name: "scale_img_bnorm4"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}

## L2 Norm
layer {
  name: "img_l2norm"
  type: "Norm"
  bottom: "img_bnorm4"
  top: "img_l2norm"
}


## text branch
layer {
  name: "text_fc1"
  type: "InnerProduct"
  bottom: "text_data_bnorm"
  top: "text_fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "text_relu1"
  type: "ReLU"
  bottom: "text_fc1"
  top: "text_fc1"
}
layer {
  name: "text_drop1"
  type: "Dropout"
  bottom: "text_fc1"
  top: "text_fc1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "text_fc2"
  type: "InnerProduct"
  bottom: "text_fc1"
  top: "text_fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "text_fc2"
   top: "text_bnorm2"
   name: "text_bnorm2"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_bnorm2"
   top: "text_bnorm2"
   name: "scale_text_bnorm2"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "text_relu2"
  type: "ReLU"
  bottom: "text_bnorm2"
  top: "text_bnorm2"
}

layer {
  name: "text_fc3_t0"
  type: "InnerProduct"
  bottom: "text_bnorm2"
  top: "text_fc3_t0"
  param {
    name: "text_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "text_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "text_fc3_t0"
   top: "text_bnorm3_t0"
   name: "text_bnorm3_t0"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_bnorm3_t0"
   top: "text_bnorm3_t0"
   name: "scale_text_bnorm3_t0"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "text_relu3_t0"
  type: "ReLU"
  bottom: "text_bnorm3_t0"
  top: "text_bnorm3_t0"
}
## identity addition
layer {
   bottom: "text_bnorm2"
   bottom: "text_bnorm3_t0"
   top: "text_fc3_t0_res"
   name: "text_fc3_t0_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## recurrent, t=1
layer {
  name: "text_fc3_t1"
  type: "InnerProduct"
  bottom: "text_fc3_t0_res"
  top: "text_fc3_t1"
  param {
    name: "text_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "text_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "text_fc3_t1"
   top: "text_bnorm3_t1"
   name: "text_bnorm3_t1"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_bnorm3_t1"
   top: "text_bnorm3_t1"
   name: "scale_text_bnorm3_t1"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "text_relu3_t1"
  type: "ReLU"
  bottom: "text_bnorm3_t1"
  top: "text_bnorm3_t1"
}
## identity addition
layer {
   bottom: "text_fc3_t0_res"
   bottom: "text_bnorm3_t1"
   top: "text_fc3_t1_res"
   name: "text_fc3_t1_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## recurrent, t=2
layer {
  name: "text_fc3_t2"
  type: "InnerProduct"
  bottom: "text_fc3_t1_res"
  top: "text_fc3_t2"
  param {
    name: "text_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "text_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "text_fc3_t2"
   top: "text_bnorm3_t2"
   name: "text_bnorm3_t2"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_bnorm3_t2"
   top: "text_bnorm3_t2"
   name: "scale_text_bnorm3_t2"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "text_relu3_t2"
  type: "ReLU"
  bottom: "text_bnorm3_t2"
  top: "text_bnorm3_t2"
}
## identity addition
layer {
   bottom: "text_fc3_t1_res"
   bottom: "text_bnorm3_t2"
   top: "text_fc3_t2_res"
   name: "text_fc3_t2_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## recurrent, t=3
layer {
  name: "text_fc3_t3"
  type: "InnerProduct"
  bottom: "text_fc3_t2_res"
  top: "text_fc3_t3"
  param {
    name: "text_fc3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "text_fc3_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "text_fc3_t3"
   top: "text_bnorm3_t3"
   name: "text_bnorm3_t3"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_bnorm3_t3"
   top: "text_bnorm3_t3"
   name: "scale_text_bnorm3_t3"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "text_relu3_t3"
  type: "ReLU"
  bottom: "text_bnorm3_t3"
  top: "text_bnorm3_t3"
}
## identity addition
layer {
   bottom: "text_fc3_t2_res"
   bottom: "text_bnorm3_t3"
   top: "text_fc3_t3_res"
   name: "text_fc3_t3_res"
   type: "Eltwise"
   eltwise_param {
     operation: SUM
   }
}

## Convolutional Fusion
layer {
  name: "text_fc3_t0_res_re"
  type: "Reshape"
  bottom: "text_fc3_t0_res"
  top: "text_fc3_t0_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
layer {
  name: "text_fc3_t1_res_re"
  type: "Reshape"
  bottom: "text_fc3_t1_res"
  top: "text_fc3_t1_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
layer {
  name: "text_fc3_t2_res_re"
  type: "Reshape"
  bottom: "text_fc3_t2_res"
  top: "text_fc3_t2_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
layer {
  name: "text_fc3_t3_res_re"
  type: "Reshape"
  bottom: "text_fc3_t3_res"
  top: "text_fc3_t3_res_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 1
      dim: 512
      dim: 1
    } 
  }
}
## Stack 
layer {
  name: "text_fc3_res_stack"
  bottom: "text_fc3_t0_res_re"
  bottom: "text_fc3_t1_res_re"
  bottom: "text_fc3_t2_res_re"
  bottom: "text_fc3_t3_res_re"
  top: "text_fc3_res_stack"
  type: "Concat"
  concat_param {
    concat_dim: 1
  }
}
layer { 
  name: 'text_fc3_res_weight' 
  type: "Convolution" 
  bottom: 'text_fc3_res_stack' 
  top: 'text_fc3_res_weight'
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
  convolution_param {
    num_output: 1
    kernel_size: 1
    pad: 0
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: 'text_fc3_res_weight'
   top: 'text_fc3_res_weight_bnorm'
   name: 'text_fc3_res_weight_bnorm'
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: 'text_fc3_res_weight_bnorm'
   top: 'text_fc3_res_weight_bnorm'
   name: "scale_text_fc3_res_weight_bnorm"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}
layer {
  name: "relu_text_fc3_res_weight_bnorm"
  type: "ReLU"
  bottom: 'text_fc3_res_weight_bnorm'
  top: 'text_fc3_res_weight_bnorm'
}

layer {
  name: "text_fc3_res_weight_re"
  type: "Reshape"
  bottom: 'text_fc3_res_weight_bnorm'
  top: "text_fc3_res_weight_bnorm_re"
  reshape_param { 
    shape {
      dim: 1500
      dim: 512
      dim: 1
      dim: 1
    } 
  }
}
## End for fusion module

layer {
  name: "text_fc4"
  type: "InnerProduct"
  bottom: "text_fc3_res_weight_bnorm_re"
  top: "text_fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
   bottom: "text_fc4"
   top: "text_bnorm4"
   name: "text_bnorm4"
   type: "BatchNorm"
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
   param {
     lr_mult: 0
   }
}
layer {
   bottom: "text_bnorm4"
   top: "text_bnorm4"
   name: "scale_text_bnorm4"
   type: "Scale"
   param {
     lr_mult: 1
     decay_mult: 1
   }
   param {
     lr_mult: 2
     decay_mult: 0
   }
   scale_param {
     bias_term: true
   }
}

## L2 Norm
layer {
  name: "text_l2norm"
  type: "Norm"
  bottom: "text_bnorm4"
  top: "text_l2norm"
}

## Bi-rank Loss
layer {
  name: "loss"
  type: "BiRankLoss"
  bottom: "img_l2norm"
  bottom: "label"
  bottom: "text_l2norm"
  bottom: "label"
  top: "loss"
  bi_rank_param{
    neg_num: 50
    alpha1: 1
    alpha2: 0.5
    alpha3: 2
    alpha4: 1
    margin: 0.1
  }
}


